{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Digital Futures](https://github.com/digital-futures-academy/DataScienceMasterResources/blob/main/Resources/datascience-notebook-header.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Project Environment\n",
    "\n",
    "Ultimately, the Python code written here will be extracted to scripts for execution in an automated pipeline.  To facilitate this, there is a need to set up a project environment that will allow for the execution of the code in a controlled and reproducible environment.\n",
    "\n",
    "In the initial stages of the activities, the packages needed are `requests` and `pytest`.  The `requests` package is used to make HTTP requests to the API, while `pytest` is used for testing the code we also need *BeautifulSoup* (package name `beautifulsoup4`.  In later activities, you may need to install additional packages.  To do this, add the packages to the `pip install` command below and re-run the cell.\n",
    "\n",
    "> **Remember:** The goal is to create a set of code cells that can be extracted to separate scripts for execution in an automated pipeline.  Therefore, the code should be kept in 3 distinct cells:\n",
    "> \n",
    "> - **Shell Commands**:  Used to set up the project environment\n",
    "> \n",
    "> - **Python Tests**: Used to test the Python production scripts both now and as part of the automated pipeline\n",
    "> \n",
    "> - **Python Production Code**: The Python code that will be extracted to a script to execute during the pipeline\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup Scripts\n",
    "\n",
    "If you are running this notebook after cloning and have not set up your environment to run shell commands, you will need to run the following commands in your terminal to set up the environment.\n",
    "\n",
    "> **NOTE:**  These commands need to be executed in the terminal.  \n",
    ">\n",
    "> Open a terminal at the root of your project before executing these commands\n",
    "> \n",
    "> Until your environment is set up, Jupyter Notebooks will not be able to run **shell** scripts.\n",
    "\n",
    "```sh\n",
    "# Create a virtual environment (add the command below)\n",
    "python3 -m venv .venv # Note: This command could also be python -m venv .venv # python3 and python are a symlink to the python version installed on your system\n",
    "\n",
    "# Activate the virtual environment \n",
    "source .venv/bin/activate\n",
    "\n",
    "# Install required package to execute shell commands from Jupyter Notebook\n",
    "pip install ipykernel               ## OR \n",
    "pip install -r requirements.txt     ## IF there is already a requirements.txt file CONTAINING ipykenrnel in the project\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install the necessary packages\n",
    "!pip install requests pytest beautifulsoup4\n",
    "\n",
    "# Create a requirements.txt file\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** \n",
    "> The `!` at the beginning of the lines is a special character in Jupyter Notebooks that allows you to run shell commands from the notebook.  \n",
    "> These will need to be removed from any commands that are to be exported to a `.sh` shell script file for the pipeline.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Tests\n",
    "\n",
    "Develop any tests for functions in separate cells below.  The first has been provided for you as an example, add others as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `request_to_scrape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from unittest.mock import patch\n",
    "import requests  # Assuming the production function uses the requests library\n",
    "\n",
    "dummy_url = \"https://www.example.com\"\n",
    "dummy_html = \"<html><body><h1>Hello, World!</h1></body></html>\"\n",
    "\n",
    "# Test request_to_scrape\n",
    "def test_request_to_scrape():\n",
    "    # Arrange\n",
    "    with patch('requests.get') as mock_get:\n",
    "        # Configure the mock to return a response with status_code 200\n",
    "        mock_get.return_value.status_code = 200\n",
    "\n",
    "        # Act\n",
    "        response = request_to_scrape(dummy_url)\n",
    "        \n",
    "        # Assert\n",
    "        mock_get.assert_called_once_with(dummy_url)  # Ensure the mock was called with the correct URL\n",
    "        \n",
    "def test_request_to_scrape_returns_html():\n",
    "    # Arrange\n",
    "    \n",
    "    with patch('requests.get') as mock_get:\n",
    "        # Configure the mock to return a response with status_code 200 and dummy HTML content\n",
    "        mock_get.return_value.status_code = 200\n",
    "        mock_get.return_value.text = dummy_html\n",
    "        # Act\n",
    "        result = request_to_scrape(dummy_url)\n",
    "        # Assert\n",
    "        assert result.text == dummy_html  # Check that the returned content matches the dummy HTML\n",
    "        \n",
    "def test_for_non_200_status():\n",
    "    #Arrange\n",
    "    \n",
    "    with patch('requests.get') as mock_get:\n",
    "        mock_get.return_value.status_code = 404   \n",
    "        #Act\n",
    "        result = request_to_scrape(dummy_url)\n",
    "        #Assert\n",
    "        assert result == \"Error:page not found\"\n",
    "        \n",
    "def test_request_handles_exception():\n",
    "    #Arrange\n",
    "    \n",
    "    with patch('requests.get') as mock_get:\n",
    "        mock_get.side_effect = requests.exceptions.RequestException(\"Connection Error\")\n",
    "        #Act\n",
    "        result = request_to_scrape(dummy_url)\n",
    "        #Assert\n",
    "        assert result == \"An error occurred: Connection Error\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test extract_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pytest\n",
    "\n",
    "def test_extract_element_with_tag_and_class():\n",
    "    # Arrange\n",
    "    html_doc = \"<html><body><h1 class='title'>Welcome</h1><p class='content'>Content here</p></body></html>\"\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    \n",
    "    # Act\n",
    "    result = extract_element(soup, 'h1', 'title')\n",
    "    \n",
    "    # Assert\n",
    "    assert result is not None\n",
    "    assert result.text == \"Welcome\"\n",
    "    \n",
    "def test_extract_element_with_tag_only():\n",
    "    # Arrange\n",
    "    html_doc = \"<html><body><h1 class='title'>Welcome</h1><p class='content'>Content here</p></body></html>\"\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    \n",
    "    # Act\n",
    "    result = extract_element(soup, 'p')\n",
    "    \n",
    "    # Assert\n",
    "    assert result is not None\n",
    "    assert result.text == \"Content here\"\n",
    "\n",
    "def test_extract_element_with_no_matching_class():\n",
    "    # Arrange\n",
    "    html_doc = \"<html><body><h1 class='title'>Welcome</h1><p class='content'>Content here</p></body></html>\"\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    \n",
    "    # Act\n",
    "    result = extract_element(soup, 'h1', 'nonexistent-class')\n",
    "    \n",
    "    # Assert\n",
    "    assert result is None\n",
    "\n",
    "def test_extract_element_with_no_matching_tag():\n",
    "    # Arrange\n",
    "    html_doc = \"<html><body><h1 class='title'>Welcome</h1><p class='content'>Content here</p></body></html>\"\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    \n",
    "    # Act\n",
    "    result = extract_element(soup, 'div', 'nonexistent-class')\n",
    "    \n",
    "    # Assert\n",
    "    assert result is None\n",
    "\n",
    "def test_extract_element_with_multiple_matching_elements_tag_and_class():\n",
    "    # Arrange\n",
    "    html_doc = \"<html><body><h1 class='title'>First</h1><h1 class='title'>Second</h1></body></html>\"\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    \n",
    "    # Act\n",
    "    result = extract_element(soup, 'h1', 'title')\n",
    "    \n",
    "    # Assert\n",
    "    assert result is not None\n",
    "    assert result.text == \"First\"  # The first matching element\n",
    "\n",
    "def test_extract_element_with_multiple_matching_elements_tag_only():\n",
    "    # Arrange\n",
    "    html_doc = \"<html><body><h1>First</h1><h1>Second</h1></body></html>\"\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    \n",
    "    # Act\n",
    "    result = extract_element(soup, 'h1')\n",
    "    \n",
    "    # Assert\n",
    "    assert result is not None\n",
    "    assert result.text == \"First\"  # The first matching element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests for extract_categories_and_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pytest\n",
    "\n",
    "# Test 1: Valid HTML with multiple categories\n",
    "def test_extract_categories_and_links_valid_html():\n",
    "    html_doc = \"\"\"\n",
    "    <html><body>\n",
    "    <ul class=\"categories\">\n",
    "        <li><a href=\"cat1\">Category 1</a></li>\n",
    "        <li><a href=\"cat2\">Category 2</a></li>\n",
    "        <li><a href=\"cat3\">Category 3</a></li>\n",
    "    </ul>\n",
    "    </body></html>\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    site = \"http://example.com\"\n",
    "    \n",
    "    result = extract_categories_and_links(soup, site)\n",
    "    \n",
    "    expected = {\n",
    "        \"Category 1\": \"http://example.com/cat1\",\n",
    "        \"Category 2\": \"http://example.com/cat2\",\n",
    "        \"Category 3\": \"http://example.com/cat3\"\n",
    "    }\n",
    "    \n",
    "    assert result == expected\n",
    "\n",
    "# Test 2: HTML without any categories\n",
    "def test_extract_categories_and_links_no_categories():\n",
    "    html_doc = \"\"\"\n",
    "    <html><body>\n",
    "    <ul class=\"other\">\n",
    "        <li>Item 1</li>\n",
    "        <li>Item 2</li>\n",
    "    </ul>\n",
    "    </body></html>\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    site = \"http://example.com\"\n",
    "    \n",
    "    result = extract_categories_and_links(soup, site)\n",
    "    \n",
    "    assert result == {}\n",
    "\n",
    "# Test 3: Empty HTML\n",
    "def test_extract_categories_and_links_empty_html():\n",
    "    html_doc = \"\"\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    site = \"http://example.com\"\n",
    "    \n",
    "    result = extract_categories_and_links(soup, site)\n",
    "    \n",
    "    assert result == {}\n",
    "\n",
    "# Test 4: Invalid HTML\n",
    "def test_extract_categories_and_links_invalid_html():\n",
    "    html_doc = \"<html><body><ul class='categories'><li><a href='cat1'>Category 1</a></ul></body></html>\"\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')  # Invalid HTML, missing closing tag for <li>\n",
    "    site = \"http://example.com\"\n",
    "    \n",
    "    result = extract_categories_and_links(soup, site)\n",
    "    \n",
    "    expected = {\n",
    "        \"Category 1\": \"http://example.com/cat1\"\n",
    "    }\n",
    "    \n",
    "    assert result == expected\n",
    "\n",
    "# Test 5: HTML with nested categories\n",
    "def test_extract_categories_and_links_nested_categories():\n",
    "    html_doc = \"\"\"\n",
    "    <html><body>\n",
    "    <ul class=\"categories\">\n",
    "        <li><a href=\"cat1\">Category 1</a></li>\n",
    "        <li>\n",
    "            <ul>\n",
    "                <li><a href=\"cat2\">Category 2</a></li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "    </body></html>\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    site = \"http://example.com\"\n",
    "    \n",
    "    result = extract_categories_and_links(soup, site)\n",
    "    \n",
    "    expected = {\n",
    "        \"Category 1\": \"http://example.com/cat1\",\n",
    "        \"Category 2\": \"http://example.com/cat2\"\n",
    "    }\n",
    "    \n",
    "    assert result == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the extract_book_categories Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pytest\n",
    "\n",
    "\n",
    "# Assuming extract_element and extract_categories_and_links are defined in the same module as extract_book_categories\n",
    "\n",
    "# Test 1: Correct integration of helper functions (without patching)\n",
    "def test_extract_book_categories_integration():\n",
    "    # Arrange\n",
    "    html_doc = \"\"\"\n",
    "    <html><body>\n",
    "    <div class=\"categories-list\">\n",
    "        <a href=\"cat1\">Category 1</a>\n",
    "        <a href=\"cat2\">Category 2</a>\n",
    "    </div>\n",
    "    </body></html>\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    site = \"http://example.com\"\n",
    "\n",
    "    # Mocking the behavior of extract_element and extract_categories_and_links\n",
    "    mock_extract_element = lambda soup, tag, class_name: soup.find_all(tag)  # Simulating extract_element\n",
    "    mock_extract_categories_and_links = lambda categories_list, site: {\n",
    "        \"Category 1\": f\"{site}/cat1\",\n",
    "        \"Category 2\": f\"{site}/cat2\"\n",
    "    }  # Simulating extract_categories_and_links\n",
    "\n",
    "    # Act\n",
    "    # Use the mocked functions directly in the function being tested\n",
    "    categories_list = mock_extract_element(soup, 'a', None)  # Mocked call to extract_element\n",
    "    result = mock_extract_categories_and_links(categories_list, site)  # Mocked call to extract_categories_and_links\n",
    "    \n",
    "    # Assert\n",
    "    # Check if the mocked functions return the expected results\n",
    "    assert result == {\n",
    "        \"Category 1\": \"http://example.com/cat1\",\n",
    "        \"Category 2\": \"http://example.com/cat2\"\n",
    "    }\n",
    "\n",
    "# Test 2: Handling different HTML structures\n",
    "def test_extract_book_categories_invalid_structure():\n",
    "    # Arrange (HTML without expected category structure)\n",
    "    html_doc = \"\"\"\n",
    "    <html><body>\n",
    "    <div class=\"other\">\n",
    "        <p>Some random text</p>\n",
    "    </div>\n",
    "    </body></html>\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    site = \"http://example.com\"\n",
    "    \n",
    "    # Act\n",
    "    result = extract_book_categories(soup, site)\n",
    "    \n",
    "    # Assert (Expected result when no categories are found)\n",
    "    assert result == {}\n",
    "\n",
    "def test_extract_book_categories_empty_html():\n",
    "    # Arrange (Empty HTML)\n",
    "    html_doc = \"\"\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    site = \"http://example.com\"\n",
    "    \n",
    "    # Act\n",
    "    result = extract_book_categories(soup, site)\n",
    "    \n",
    "    # Assert (Expected result when no categories are found)\n",
    "    assert result == {}\n",
    "\n",
    "def test_extract_book_categories_invalid_html():\n",
    "    # Arrange (Malformed HTML)\n",
    "    html_doc = \"<html><body><ul class='categories'><li><a href='cat1'>Category 1</a></ul></body></html>\"\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')  # Invalid HTML, missing closing tag for <li>\n",
    "    site = \"http://example.com\"\n",
    "    \n",
    "    # Act\n",
    "    result = extract_book_categories(soup, site)\n",
    "    \n",
    "    # Assert (Expected result when a valid category is found)\n",
    "    assert result == {\n",
    "        \"Category 1\": \"http://example.com/cat1\"\n",
    "    }\n",
    "\n",
    "# Test 3: Returning the expected results\n",
    "def test_extract_book_categories_returns_expected_results():\n",
    "    # Arrange (Valid HTML with categories)\n",
    "    html_doc = \"\"\"\n",
    "    <html><body>\n",
    "    <div class=\"categories-list\">\n",
    "        <a href=\"cat1\">Category 1</a>\n",
    "        <a href=\"cat2\">Category 2</a>\n",
    "    </div>\n",
    "    </body></html>\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    site = \"http://example.com\"\n",
    "    \n",
    "    # Act\n",
    "    result = extract_book_categories(soup, site)\n",
    "    \n",
    "    # Assert\n",
    "    assert result == {\n",
    "        \"Category 1\": \"http://example.com/cat1\",\n",
    "        \"Category 2\": \"http://example.com/cat2\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the tests\n",
    "\n",
    "Run the cell containing the `ipytest.run()` command to execute the tests.  The tests should all fail until you have written the production code.\n",
    "\n",
    "Don't forget to run the installation and initialisation cell too on the first time you run the tests!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Python Production Code\n",
    "\n",
    "\n",
    "Develop any functions for use as production code in separate cells below. The first has been provided as an example under the Production Constants, add others as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRODUCTION CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRODUCTION CONSTANTS\n",
    "\n",
    "# Constants for status messages\n",
    "STATUS_SUCCESS = \"success\"\n",
    "STATUS_ERROR = \"error\"\n",
    "ERROR_NOT_HTML = \"The response is not HTML\"\n",
    "ERROR_REQUEST_FAILED = \"Request failed for URL\"\n",
    "ERROR_UNEXPECTED = \"Unexpected error for URL\"\n",
    "\n",
    "# HTML Parser\n",
    "HTML_PARSER = \"html.parser\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `request_to_scrape` Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_to_scrape(url: str): \n",
    "    try:  \n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            return response\n",
    "        else:\n",
    "            return \"Error:page not found\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"An error occurred: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `extract_book_categories` Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_book_categories(html, site: str, html_parser: str = 'html.parser'):\n",
    "    \"\"\"\n",
    "    Extracts book categories and their links from the given HTML.\n",
    "    \n",
    "    Args:\n",
    "        html (str or response object): The HTML content or response object to parse.\n",
    "        site (str): The base URL of the website.\n",
    "        html_parser (str): The parser to use for BeautifulSoup.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary of category names as keys and their full URLs as values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # If `html` is a response object, extract the content; otherwise, assume it's a raw HTML string\n",
    "        html_content = html.content if hasattr(html, 'content') else html\n",
    "        #print(html_content)\n",
    "        # Parse the HTML\n",
    "        soup = BeautifulSoup(html_content, html_parser) if html_content else None\n",
    "        \n",
    "        # Handle empty or invalid HTML\n",
    "        if not soup:\n",
    "            return {}\n",
    "\n",
    "        # Extract the navigation list\n",
    "        nav_list = extract_element(soup, 'ul', 'nav nav-list')\n",
    "\n",
    "        # Handle cases where the navigation list is not found\n",
    "        if not nav_list:\n",
    "            return {}\n",
    "\n",
    "        # Extract categories and links\n",
    "        categories = extract_categories_and_links(nav_list, site)\n",
    "        \n",
    "        return categories\n",
    "    except Exception as e:\n",
    "        # Gracefully handle exceptions and return an empty dictionary\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `extract_element` Production code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_element(soup,tag,class_name=None):\n",
    "    if class_name!= None:\n",
    "        #print(tag,class_name)\n",
    "        found_elem = soup.find(tag,class_=class_name)\n",
    "        return(found_elem)\n",
    "    else: \n",
    "        return(soup.find(tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `extract_categories_and_links` Production code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_categories_and_links(categories_list,site):\n",
    "    categories = {}\n",
    "    for link in categories_list.find_all('a'):\n",
    "        category_name = link.get_text(strip=True)\n",
    "        category_href = link.get('href')\n",
    "        categories[category_name] = {'link':f\"{site}/{category_href}\"} if category_href else None\n",
    "    return categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Python Execution Code\n",
    "\n",
    "Develop any code to call the developed functions below.  Add additional cells so you don't need to re-run all of the code when you develop further scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = \"http://books.toscrape.com\"\n",
    "home_page = request_to_scrape(site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Books': {'link': 'http://books.toscrape.com/catalogue/category/books_1/index.html'}, 'Travel': {'link': 'http://books.toscrape.com/catalogue/category/books/travel_2/index.html'}, 'Mystery': {'link': 'http://books.toscrape.com/catalogue/category/books/mystery_3/index.html'}, 'Historical Fiction': {'link': 'http://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html'}, 'Sequential Art': {'link': 'http://books.toscrape.com/catalogue/category/books/sequential-art_5/index.html'}, 'Classics': {'link': 'http://books.toscrape.com/catalogue/category/books/classics_6/index.html'}, 'Philosophy': {'link': 'http://books.toscrape.com/catalogue/category/books/philosophy_7/index.html'}, 'Romance': {'link': 'http://books.toscrape.com/catalogue/category/books/romance_8/index.html'}, 'Womens Fiction': {'link': 'http://books.toscrape.com/catalogue/category/books/womens-fiction_9/index.html'}, 'Fiction': {'link': 'http://books.toscrape.com/catalogue/category/books/fiction_10/index.html'}, 'Childrens': {'link': 'http://books.toscrape.com/catalogue/category/books/childrens_11/index.html'}, 'Religion': {'link': 'http://books.toscrape.com/catalogue/category/books/religion_12/index.html'}, 'Nonfiction': {'link': 'http://books.toscrape.com/catalogue/category/books/nonfiction_13/index.html'}, 'Music': {'link': 'http://books.toscrape.com/catalogue/category/books/music_14/index.html'}, 'Default': {'link': 'http://books.toscrape.com/catalogue/category/books/default_15/index.html'}, 'Science Fiction': {'link': 'http://books.toscrape.com/catalogue/category/books/science-fiction_16/index.html'}, 'Sports and Games': {'link': 'http://books.toscrape.com/catalogue/category/books/sports-and-games_17/index.html'}, 'Add a comment': {'link': 'http://books.toscrape.com/catalogue/category/books/add-a-comment_18/index.html'}, 'Fantasy': {'link': 'http://books.toscrape.com/catalogue/category/books/fantasy_19/index.html'}, 'New Adult': {'link': 'http://books.toscrape.com/catalogue/category/books/new-adult_20/index.html'}, 'Young Adult': {'link': 'http://books.toscrape.com/catalogue/category/books/young-adult_21/index.html'}, 'Science': {'link': 'http://books.toscrape.com/catalogue/category/books/science_22/index.html'}, 'Poetry': {'link': 'http://books.toscrape.com/catalogue/category/books/poetry_23/index.html'}, 'Paranormal': {'link': 'http://books.toscrape.com/catalogue/category/books/paranormal_24/index.html'}, 'Art': {'link': 'http://books.toscrape.com/catalogue/category/books/art_25/index.html'}, 'Psychology': {'link': 'http://books.toscrape.com/catalogue/category/books/psychology_26/index.html'}, 'Autobiography': {'link': 'http://books.toscrape.com/catalogue/category/books/autobiography_27/index.html'}, 'Parenting': {'link': 'http://books.toscrape.com/catalogue/category/books/parenting_28/index.html'}, 'Adult Fiction': {'link': 'http://books.toscrape.com/catalogue/category/books/adult-fiction_29/index.html'}, 'Humor': {'link': 'http://books.toscrape.com/catalogue/category/books/humor_30/index.html'}, 'Horror': {'link': 'http://books.toscrape.com/catalogue/category/books/horror_31/index.html'}, 'History': {'link': 'http://books.toscrape.com/catalogue/category/books/history_32/index.html'}, 'Food and Drink': {'link': 'http://books.toscrape.com/catalogue/category/books/food-and-drink_33/index.html'}, 'Christian Fiction': {'link': 'http://books.toscrape.com/catalogue/category/books/christian-fiction_34/index.html'}, 'Business': {'link': 'http://books.toscrape.com/catalogue/category/books/business_35/index.html'}, 'Biography': {'link': 'http://books.toscrape.com/catalogue/category/books/biography_36/index.html'}, 'Thriller': {'link': 'http://books.toscrape.com/catalogue/category/books/thriller_37/index.html'}, 'Contemporary': {'link': 'http://books.toscrape.com/catalogue/category/books/contemporary_38/index.html'}, 'Spirituality': {'link': 'http://books.toscrape.com/catalogue/category/books/spirituality_39/index.html'}, 'Academic': {'link': 'http://books.toscrape.com/catalogue/category/books/academic_40/index.html'}, 'Self Help': {'link': 'http://books.toscrape.com/catalogue/category/books/self-help_41/index.html'}, 'Historical': {'link': 'http://books.toscrape.com/catalogue/category/books/historical_42/index.html'}, 'Christian': {'link': 'http://books.toscrape.com/catalogue/category/books/christian_43/index.html'}, 'Suspense': {'link': 'http://books.toscrape.com/catalogue/category/books/suspense_44/index.html'}, 'Short Stories': {'link': 'http://books.toscrape.com/catalogue/category/books/short-stories_45/index.html'}, 'Novels': {'link': 'http://books.toscrape.com/catalogue/category/books/novels_46/index.html'}, 'Health': {'link': 'http://books.toscrape.com/catalogue/category/books/health_47/index.html'}, 'Politics': {'link': 'http://books.toscrape.com/catalogue/category/books/politics_48/index.html'}, 'Cultural': {'link': 'http://books.toscrape.com/catalogue/category/books/cultural_49/index.html'}, 'Erotica': {'link': 'http://books.toscrape.com/catalogue/category/books/erotica_50/index.html'}, 'Crime': {'link': 'http://books.toscrape.com/catalogue/category/books/crime_51/index.html'}}\n"
     ]
    }
   ],
   "source": [
    "categories = extract_book_categories(home_page,site)\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Books': {'link': 'http://books.toscrape.com/catalogue/category/books_1/index.html', 'number_of_books': 1000}, 'Travel': {'link': 'http://books.toscrape.com/catalogue/category/books/travel_2/index.html', 'number_of_books': 11}, 'Mystery': {'link': 'http://books.toscrape.com/catalogue/category/books/mystery_3/index.html', 'number_of_books': 32}, 'Historical Fiction': {'link': 'http://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html', 'number_of_books': 26}, 'Sequential Art': {'link': 'http://books.toscrape.com/catalogue/category/books/sequential-art_5/index.html', 'number_of_books': 75}, 'Classics': {'link': 'http://books.toscrape.com/catalogue/category/books/classics_6/index.html', 'number_of_books': 19}, 'Philosophy': {'link': 'http://books.toscrape.com/catalogue/category/books/philosophy_7/index.html', 'number_of_books': 11}, 'Romance': {'link': 'http://books.toscrape.com/catalogue/category/books/romance_8/index.html', 'number_of_books': 35}, 'Womens Fiction': {'link': 'http://books.toscrape.com/catalogue/category/books/womens-fiction_9/index.html', 'number_of_books': 17}, 'Fiction': {'link': 'http://books.toscrape.com/catalogue/category/books/fiction_10/index.html', 'number_of_books': 65}, 'Childrens': {'link': 'http://books.toscrape.com/catalogue/category/books/childrens_11/index.html', 'number_of_books': 29}, 'Religion': {'link': 'http://books.toscrape.com/catalogue/category/books/religion_12/index.html', 'number_of_books': 7}, 'Nonfiction': {'link': 'http://books.toscrape.com/catalogue/category/books/nonfiction_13/index.html', 'number_of_books': 110}, 'Music': {'link': 'http://books.toscrape.com/catalogue/category/books/music_14/index.html', 'number_of_books': 13}, 'Default': {'link': 'http://books.toscrape.com/catalogue/category/books/default_15/index.html', 'number_of_books': 152}, 'Science Fiction': {'link': 'http://books.toscrape.com/catalogue/category/books/science-fiction_16/index.html', 'number_of_books': 16}, 'Sports and Games': {'link': 'http://books.toscrape.com/catalogue/category/books/sports-and-games_17/index.html', 'number_of_books': 5}, 'Add a comment': {'link': 'http://books.toscrape.com/catalogue/category/books/add-a-comment_18/index.html', 'number_of_books': 67}, 'Fantasy': {'link': 'http://books.toscrape.com/catalogue/category/books/fantasy_19/index.html', 'number_of_books': 48}, 'New Adult': {'link': 'http://books.toscrape.com/catalogue/category/books/new-adult_20/index.html', 'number_of_books': 6}, 'Young Adult': {'link': 'http://books.toscrape.com/catalogue/category/books/young-adult_21/index.html', 'number_of_books': 54}, 'Science': {'link': 'http://books.toscrape.com/catalogue/category/books/science_22/index.html', 'number_of_books': 14}, 'Poetry': {'link': 'http://books.toscrape.com/catalogue/category/books/poetry_23/index.html', 'number_of_books': 19}, 'Paranormal': {'link': 'http://books.toscrape.com/catalogue/category/books/paranormal_24/index.html', 'number_of_books': 1}, 'Art': {'link': 'http://books.toscrape.com/catalogue/category/books/art_25/index.html', 'number_of_books': 8}, 'Psychology': {'link': 'http://books.toscrape.com/catalogue/category/books/psychology_26/index.html', 'number_of_books': 7}, 'Autobiography': {'link': 'http://books.toscrape.com/catalogue/category/books/autobiography_27/index.html', 'number_of_books': 9}, 'Parenting': {'link': 'http://books.toscrape.com/catalogue/category/books/parenting_28/index.html', 'number_of_books': 1}, 'Adult Fiction': {'link': 'http://books.toscrape.com/catalogue/category/books/adult-fiction_29/index.html', 'number_of_books': 1}, 'Humor': {'link': 'http://books.toscrape.com/catalogue/category/books/humor_30/index.html', 'number_of_books': 10}, 'Horror': {'link': 'http://books.toscrape.com/catalogue/category/books/horror_31/index.html', 'number_of_books': 17}, 'History': {'link': 'http://books.toscrape.com/catalogue/category/books/history_32/index.html', 'number_of_books': 18}, 'Food and Drink': {'link': 'http://books.toscrape.com/catalogue/category/books/food-and-drink_33/index.html', 'number_of_books': 30}, 'Christian Fiction': {'link': 'http://books.toscrape.com/catalogue/category/books/christian-fiction_34/index.html', 'number_of_books': 6}, 'Business': {'link': 'http://books.toscrape.com/catalogue/category/books/business_35/index.html', 'number_of_books': 12}, 'Biography': {'link': 'http://books.toscrape.com/catalogue/category/books/biography_36/index.html', 'number_of_books': 5}, 'Thriller': {'link': 'http://books.toscrape.com/catalogue/category/books/thriller_37/index.html', 'number_of_books': 11}, 'Contemporary': {'link': 'http://books.toscrape.com/catalogue/category/books/contemporary_38/index.html', 'number_of_books': 3}, 'Spirituality': {'link': 'http://books.toscrape.com/catalogue/category/books/spirituality_39/index.html', 'number_of_books': 6}, 'Academic': {'link': 'http://books.toscrape.com/catalogue/category/books/academic_40/index.html', 'number_of_books': 1}, 'Self Help': {'link': 'http://books.toscrape.com/catalogue/category/books/self-help_41/index.html', 'number_of_books': 5}, 'Historical': {'link': 'http://books.toscrape.com/catalogue/category/books/historical_42/index.html', 'number_of_books': 2}, 'Christian': {'link': 'http://books.toscrape.com/catalogue/category/books/christian_43/index.html', 'number_of_books': 3}, 'Suspense': {'link': 'http://books.toscrape.com/catalogue/category/books/suspense_44/index.html', 'number_of_books': 1}, 'Short Stories': {'link': 'http://books.toscrape.com/catalogue/category/books/short-stories_45/index.html', 'number_of_books': 1}, 'Novels': {'link': 'http://books.toscrape.com/catalogue/category/books/novels_46/index.html', 'number_of_books': 1}, 'Health': {'link': 'http://books.toscrape.com/catalogue/category/books/health_47/index.html', 'number_of_books': 4}, 'Politics': {'link': 'http://books.toscrape.com/catalogue/category/books/politics_48/index.html', 'number_of_books': 3}, 'Cultural': {'link': 'http://books.toscrape.com/catalogue/category/books/cultural_49/index.html', 'number_of_books': 1}, 'Erotica': {'link': 'http://books.toscrape.com/catalogue/category/books/erotica_50/index.html', 'number_of_books': 1}, 'Crime': {'link': 'http://books.toscrape.com/catalogue/category/books/crime_51/index.html', 'number_of_books': 1}}\n"
     ]
    }
   ],
   "source": [
    "for category in categories.keys():\n",
    "    extract_category_data(categories[category])\n",
    "\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract_category_data Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_category_data(category,get_book_data=False):\n",
    "    #print(category)\n",
    "    category_page = request_to_scrape(category['link'])\n",
    "    #print(category_page.content)\n",
    "    soup = BeautifulSoup(category_page.content,HTML_PARSER)\n",
    "    num_of_books_in_category = extract_number_in_category(soup)\n",
    "    #print(num_of_books_in_category)\n",
    "    category['number_of_books'] = num_of_books_in_category\n",
    "    \n",
    "    return(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract_number_in_category Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number_in_category(category_page):\n",
    "    form = extract_element(category_page,'form','form-horizontal')\n",
    "    num_of_books_in_category = int(extract_element(form,'strong').get_text(strip=True))\n",
    "    return(num_of_books_in_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Test and Linting Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run `pytest` scripts in a Jupyter Notebook cell, we need to install the `ipytest` package.  This package is NOT required for a pipeline and therefore it can be removed from the `requirements.txt` file before adding the production code to the pipeline.\n",
    "\n",
    "To run linting, we need to install 2 packages `nbqa` and `flake8`.  We will make sure that `flake8` is included in the `requirements.txt` file when constructing the pipeline so that we can lint as part of the pipeline tests.\n",
    "\n",
    "Run the following cell to install the `ipytest`, `nbqa` and `flake8` packages and a coverage package to help determine if all of your production code is executed during the tests!\n",
    "\n",
    "This cell only needs to be run once (or after restarting the notebook kernel) to set up the environment for testing and linting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install the `ipytest`, `nbqa` and `flake8` packages\n",
    "!pip install ipytest nbqa flake8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up `ipytest` to execute `pytest` scripts in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure ipytest for Jupyter Notebook\n",
    "\n",
    "import ipytest\n",
    "ipytest.autoconfig(rewrite_asserts=True, magics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a *config* file for `flake8`\n",
    "\n",
    "Run this script to create a file in your project root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Create a config file and ignore some flake8 rules\n",
    "!echo \"[flake8]\" > .flake8\n",
    "!echo \"ignore = E402, W291, F811\" >> .flake8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the tests and linting in the Jupyter Notebook\n",
    "\n",
    "Run the following cell ***EVERY TIME*** you want to run the tests and linting that you have written in the *Python Tests* cell above.\n",
    "\n",
    ">**Note:**\n",
    ">\n",
    "> This entire section does not need to be part of any pipeline scripts.  \n",
    "> It is only required for the Jupyter Notebook environment during development.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the tests\n",
    "ipytest.run(\"-vv\", \"-ss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the linter\n",
    "\n",
    "Run this script each time you want to lint your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Run the linter\n",
    "!nbqa flake8 --show-source --format=pylint webscraping.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
